<!-- TOC -->

- [项目环境架构](#项目环境架构)
- [docker常用命令](#docker常用命令)
    - [基本命令](#基本命令)
    - [组合命令](#组合命令)
- [docker搭建MySQL集群](#docker搭建mysql集群)
    - [集群方案介绍](#集群方案介绍)
    - [PXC集群安装](#pxc集群安装)
    - [数据库负载均衡](#数据库负载均衡)
    - [实现负载均衡高可用](#实现负载均衡高可用)
    - [热备份数据](#热备份数据)
    - [冷还原数据 停止其余4个节点，并删除节点](#冷还原数据-停止其余4个节点并删除节点)
    - [总结](#总结)
- [docker搭建redis集群](#docker搭建redis集群)
- [部署后端Springboot项目到docker](#部署后端springboot项目到docker)
    - [Java项目运行](#java项目运行)
    - [Nginx负载均衡](#nginx负载均衡)

<!-- /TOC -->
## 项目环境架构
1. 前台通过两台nginx指向四个前端node项目
2. 前端四个node项目再通过两个nginx指向四个后端项目
3. 后端项目通过两个HA指向四个MySQL
4. 同时后端依赖三个Redis节点搭建的集群

## docker常用命令

### 基本命令
1. `yum install update` 更新软件包
2. `yum install -y docker` 安装docker软件
3. `service docker start|restart|stop` 开启|重启|停止 docker服务
4. `docker search image_name` 搜索镜像
5. `docker pull image_name` 下载镜像
6. `docker images` 查看镜像
7. `docker rmi image_name` 删除镜像 
8. `docker run 启动参数 镜像名称` 运行容器
9. `docker ps -a` 查看容器列表
10. `docker stop|pause|unpause 容器ID` 停止|挂起|恢复 容器
11. `docker inspect 容器ID` 查看容器信息
12. `docker rm 容器ID` 删除容器
13. `docker volume create|rm|inspect 数据卷名称` 创建|删除|查看 数据卷
14. `docker network ls` 查看网络信息
15. `docker network create --subnet=网段 网络名称` 创建一个网络
16. `docker network rm 网络名称` 移除网络

### 组合命令
1. `docker rmi $(docker images | grep "none" | awk '{print $3}')` 删除所有为none的无效镜像，去除grep的过滤后可以删除所有的镜像


## docker搭建MySQL集群

### 集群方案介绍
1. 使用`PXC(Percona XtraDB Cluster)`,使用PerconaServer(MySQL改进版，性能提升很大)
2. `PXC集群方案`读写是双向的，每个节点都能读写
3. `PXC`数据`强一致性`，在一个节点写入了数据，还需要将数据`同步到其它节点`，`提交事务`后才生效

### PXC集群安装
1. 在docker中安装PXC镜像：`docker pull percona/percona-xtradb-cluster`
2. 为PXC镜像改名: `docker tag percona/percona‐xtradb‐cluster pxc`
3. 创建net1网段：`docker network create ‐‐subnet=172.18.0.0/16 net1`
4. 创建5个数据卷：`docker volume create --name v1|v2|v3|v4|v5`
5. 创建一个备份卷：`docker volume create --name backup`
6. 创建一个5节点PXC集群,`MYSQL_ROOT_PASSWORD`指定root密码，`CLUSTER_NAME`指定集群名称，`XTRABACKUP_PASSWORD`为节点间同步密码，`-v`指定数据卷映射，宿主机与docker目录对应,`--privileged` 指定最高权限，`--name`为节点命令，`--net`指定网络，`--ip`指定当前节点ip，最后的`pxc`为镜像名称
```shell
#创建第1个MySQL节点
docker run -d -p 3316:3306 -e MYSQL_ROOT_PASSWORD=abc123456 -e CLUSTER_NAME=PXC -e XTRABACKUP_PASSWORD=abc123456 -v v1:/var/lib/mysql -v backup:/data --privileged --name=node1 --net=net1 --ip 172.18.0.2 pxc
#创建第2个MySQL节点
docker run -d -p 3326:3306 -e MYSQL_ROOT_PASSWORD=abc123456 -e CLUSTER_NAME=PXC -e XTRABACKUP_PASSWORD=abc123456 -e CLUSTER_JOIN=node1 -v v2:/var/lib/mysql --privileged --name=node2 --net=net1 --ip 172.18.0.3 pxc
#创建第3个MySQL节点
docker run -d -p 3336:3306 -e MYSQL_ROOT_PASSWORD=abc123456 -e CLUSTER_NAME=PXC -e XTRABACKUP_PASSWORD=abc123456 -e CLUSTER_JOIN=node1 -v v3:/var/lib/mysql --privileged --name=node3 --net=net1 --ip 172.18.0.4 pxc
#创建第4个MySQL节点
docker run -d -p 3346:3306 -e MYSQL_ROOT_PASSWORD=abc123456 -e CLUSTER_NAME=PXC -e XTRABACKUP_PASSWORD=abc123456 -e CLUSTER_JOIN=node1 -v v4:/var/lib/mysql --privileged --name=node4 --net=net1 --ip 172.18.0.5 pxc
#创建第5个MySQL节点
docker run -d -p 3356:3306 -e MYSQL_ROOT_PASSWORD=abc123456 -e CLUSTER_NAME=PXC -e XTRABACKUP_PASSWORD=abc123456 -e CLUSTER_JOIN=node1 -v v5:/var/lib/mysql --privileged --name=node5 --net=net1 --ip 172.18.0.6 pxc

# 通过将2,3,4,5节点连接到1节点，形成PXC集群，五个节点都可读可写
```

### 数据库负载均衡
虽然有集群了，但是单节点请求的话还是负载高，性能差，所以需要`负载均衡`了

1. 安装haproxy镜像: `docker pull haproxy`
2. 创建一个无权限MySQL用户，用作haproxy的心跳监控：`create user 'haproxy'@'%' IDENTIFIED BY '';`
3. 在宿主机上编写Haproxy配置文件
```properties
global
	#工作目录
	chroot /usr/local/etc/haproxy
	#日志文件，使用rsyslog服务中local5日志设备（/var/log/local5），等级info
	log 127.0.0.1 local5 info
	#守护进程运行
	daemon

defaults
	log	global
	mode	http
	#日志格式
	option	httplog
	#日志中不记录负载均衡的心跳检测记录
	option	dontlognull
    #连接超时（毫秒）
	timeout connect 5000
    #客户端超时（毫秒）
	timeout client  50000
	#服务器超时（毫秒）
    timeout server  50000

#监控界面	
listen  admin_stats
	#监控界面的访问的IP和端口
	bind  0.0.0.0:8888
	#访问协议
    mode        http
	#URI相对地址
    stats uri   /dbs
	#统计报告格式
    stats realm     Global\ statistics
	#登陆帐户信息
    stats auth  admin:abc123456
#数据库负载均衡
listen  proxy-mysql
	#访问的IP和端口
	bind  0.0.0.0:3306  
    #网络协议
	mode  tcp
	#负载均衡算法（轮询算法）
	#轮询算法：roundrobin
	#权重算法：static-rr
	#最少连接算法：leastconn
	#请求源IP算法：source 
    balance  roundrobin
	#日志格式
    option  tcplog
	#在MySQL中创建一个没有权限的haproxy用户，密码为空。Haproxy使用这个账户对MySQL数据库心跳检测
    option  mysql-check user haproxy
    server  MySQL_1 172.18.0.2:3306 check weight 1 maxconn 2000  
    server  MySQL_2 172.18.0.3:3306 check weight 1 maxconn 2000  
	server  MySQL_3 172.18.0.4:3306 check weight 1 maxconn 2000 
	server  MySQL_4 172.18.0.5:3306 check weight 1 maxconn 2000
	server  MySQL_5 172.18.0.6:3306 check weight 1 maxconn 2000
	#使用keepalive检测死链
    option  tcpka  
```
4. 创建两个Haproxy容器
```shell
#创建第1个Haproxy负载均衡服务器
docker run -it -d -p 4001:8888 -p 4002:3306 -v /home/soft/haproxy:/usr/local/etc/haproxy --name h1 --privileged --net=net1 --ip 172.18.0.7 haproxy
#进入h1容器，启动Haproxy
docker exec -it h1 bash
haproxy -f /usr/local/etc/haproxy/haproxy.cfg


#创建第2个Haproxy负载均衡服务器
docker run -it -d -p 4003:8888 -p 4004:3306 -v /home/soft/haproxy:/usr/local/etc/haproxy --name h2 --privileged --net=net1 --ip 172.18.0.8 haproxy
#进入h2容器，启动Haproxy
docker exec -it h2 bash
haproxy -f /usr/local/etc/haproxy/haproxy.cfg
```

### 实现负载均衡高可用
1. 进入Haproxy容器内安装keepalived，设置虚拟IP
```shell
#进入h1容器
docker exec -it h1 bash
#更新软件包
apt-get update
#安装VIM
apt-get install vim
#安装Keepalived
apt-get install keepalived
#编辑Keepalived配置文件（参考下方配置文件）
vim /etc/keepalived/keepalived.conf
#启动Keepalived
service keepalived start
#宿主机执行ping命令
ping 172.18.0.201
```
配置文件如下
```properties
vrrp_instance  VI_1 {
    state  MASTER
    interface  eth0
    virtual_router_id  51
    priority  100
    advert_int  1
    authentication {
        auth_type  PASS
        auth_pass  123456
    }
    virtual_ipaddress {
        172.18.0.201
    }
}
```

h2容器
```shell
#进入h2容器
docker exec -it h2 bash
#更新软件包
apt-get update
#安装VIM
apt-get install vim
#安装Keepalived
apt-get install keepalived
#编辑Keepalived配置文件
vim /etc/keepalived/keepalived.conf
#启动Keepalived
service keepalived start
#宿主机执行ping命令
ping 172.18.0.201
```

配置文件内容如下：
```properties
vrrp_instance  VI_1 {
    state  MASTER
    interface  eth0
    virtual_router_id  51
    priority  100
    advert_int  1
    authentication {
        auth_type  PASS
        auth_pass  123456
    }
    virtual_ipaddress {
        172.18.0.201
    }
}
```

2. 宿主机安装Keepalived，实现双击热备
```shell
#宿主机执行安装Keepalived
yum -y install keepalived
#修改Keepalived配置文件
vi /etc/keepalived/keepalived.conf
#启动Keepalived
service keepalived start
```

配置文件如下：
```conf
vrrp_instance VI_1 {
    state MASTER
    interface ens33
    virtual_router_id 51
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {
        192.168.99.150
    }
}
​
virtual_server 192.168.99.150 8888 {
    delay_loop 3
    lb_algo rr 
    lb_kind NAT
    persistence_timeout 50
    protocol TCP
​
    real_server 172.18.0.201 8888 {
        weight 1
    }
}
​
virtual_server 192.168.99.150 3306 {
    delay_loop 3
    lb_algo rr 
    lb_kind NAT
    persistence_timeout 50
    protocol TCP
​
    real_server 172.18.0.201 3306 {
        weight 1
    }
}
```

### 热备份数据
```shell
#进入node1容器
docker exec -it node1 bash
#更新软件包
apt-get update
#安装热备工具
apt-get install percona-xtrabackup-24
#全量热备
innobackupex --user=root --password=abc123456 /data/backup/full
```

### 冷还原数据 停止其余4个节点，并删除节点
```
docker stop node2
docker stop node3
docker stop node4
docker stop node5
docker rm node2
docker rm node3
docker rm node4
docker rm node5
```

node1容器中删除MySQL的数据
```shell
#删除数据
rm -rf /var/lib/mysql/*
#清空事务
innobackupex --user=root --password=abc123456 --apply-back /data/backup/full/2018-04-15_05-09-07/
#还原数据
innobackupex --user=root --password=abc123456 --copy-back  /data/backup/full/2018-04-15_05-09-07/
```

### 总结
keepalived在公有云宿主机中没办法配置虚拟IP，是个问题

## docker搭建redis集群
1. 安装redis镜像:`docker pull yyyyttttwwww/redis`
2. 创建net2网段：`docker network create --subnet=172.19.0.0/16 net2`
3. 创建6节点Redis容器
```shell
docker run -it -d --name r1 -p 5001:6379 --net=net2 --ip 172.19.0.2 redis bash
docker run -it -d --name r2 -p 5002:6379 --net=net2 --ip 172.19.0.3 redis bash
docker run -it -d --name r3 -p 5003:6379 --net=net2 --ip 172.19.0.4 redis bash
docker run -it -d --name r4 -p 5004:6379 --net=net2 --ip 172.19.0.5 redis bash
docker run -it -d --name r5 -p 5005:6379 --net=net2 --ip 172.19.0.6 redis bash
docker run -it -d --name r6 -p 5006:6379 --net=net2 --ip 172.19.0.7 redis bash
```

4. 进入每个节点（`docker exec -it r1 bash`）,修改redis.conf使得可以后台启动，aof日志等，然后`redis-server redis.conf`通过配置启动
5. 创建集群
```shell
./redis-trib.rb create --replicas 1 172.19.0.2:6379 172.19.0.3:6379 172.19.0.4:6379 172.19.0.5:6379 172.19.0.6:6379 172.19.0.7:6379
```

6. `出错了`，不知道为什么会报这个错:`[ERR] Sorry, can't connect to node 172.19.0.2:6379`



## 部署后端Springboot项目到docker

### Java项目运行
1. 初始化三个Java Docker容器：`docker pull java && docker run -it -d --name j1|j2|j3 --net=host java`
2. 从git拉取项目到容器中：`git clone xxxxx@xx.xxx`
3. 配置好之后打包jar：`mvn clean package -Dmaven.test.skip=true`
4. 后台运行jar：`nohup java -jar xxx-1.0.0.jar --server.port=10001 &`
5. 依次类推再配置两台


### Nginx负载均衡
1. 安装镜像：`docker pull nginx`
2. 宿主机创建`/home/n1/nginx.conf`，`/home/n2/nginx.conf`,n2只需要修改一下端口
```conf
user  nginx;
worker_processes  1;

error_log  /var/log/nginx/error.log warn;
pid        /var/run/nginx.pid;


events {
    worker_connections  1024;
}


http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log  /var/log/nginx/access.log  main;

    sendfile        on;
    #tcp_nopush     on;

    keepalive_timeout  65;

    #gzip  on;
	
	proxy_redirect          off;
	proxy_set_header        Host $host;
	proxy_set_header        X-Real-IP $remote_addr;
	proxy_set_header        X-Forwarded-For $proxy_add_x_forwarded_for;
	client_max_body_size    10m;
	client_body_buffer_size   128k;
	proxy_connect_timeout   5s;
	proxy_send_timeout      5s;
	proxy_read_timeout      5s;
	proxy_buffer_size        4k;
	proxy_buffers           4 32k;
	proxy_busy_buffers_size  64k;
	proxy_temp_file_write_size 64k;
	
	upstream tomcat {
		server 118.126.92.128:10001;
		server 118.126.92.128:10002;
		server 118.126.92.128:10003;
	}
	server {
        listen       6101;
        server_name  118.126.92.128; 
        location / {  
            proxy_pass   http://tomcat;
            index  index.html index.htm;  
        }  

    }
}
```

3. 运行命令创建节点
```shell
docker run -it -d --name n1 -v /home/n1/nginx.conf:/etc/nginx/nginx.conf --net=host --privileged nginx
docker run -it -d --name n2 -v /home/n2/nginx.conf:/etc/nginx/nginx.conf --net=host --privileged nginx
```

4. 然后docker的nginx就会负载到java后端项目了，最后需要用keepalived实现高可用